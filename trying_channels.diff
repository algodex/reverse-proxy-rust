diff --git a/src/main.rs b/src/main.rs
index 50ed979..9090020 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -27,19 +27,19 @@ use tokio::sync::RwLock;
 use tokio::task;
 use tokio::time::sleep;
 use tokio::time::Instant;
+use tokio::sync::oneshot;
+use tokio::sync::oneshot::{Sender, Receiver};
+
 type Uri = String;
 use crate::UriCacheUpdateMessage::*;
 
-
-macro_rules! debug_dbg {
-    ($($arg:tt)*) => (if ::std::cfg!(debug_assertions) { ::std::dbg!($($arg)*); })
+#[derive(Debug)]
+enum ResponseType {
+    Success,
+    Error
 }
 
-macro_rules! debug_println {
-    ($($arg:tt)*) => (if ::std::cfg!(debug_assertions) { ::std::println!($($arg)*); })
-}
-
-#[derive(Clone, Debug)]
+#[derive(Debug)]
 struct UriEntry {
     response_body: Option<String>,
     response_success: Option<bool>,
@@ -48,7 +48,9 @@ struct UriEntry {
     fetch_complete_time: Option<Instant>,
     last_req_time: Instant,
     request_params: RequestParams,
-    clear_timer_creation_time: Option<Instant>
+    clear_timer_creation_time: Option<Instant>,
+    channel_tx: Sender<ResponseType>,
+    channel_rx: Receiver<ResponseType>
 }
 
 #[derive(Clone, Debug)]
@@ -110,12 +112,13 @@ lazy_static! {
 
 #[async_recursion]
 async fn update_cache(msg: &UriCacheUpdateMessage) {
-    // debug_dbg!(msg);
+    // dbg!(msg);
     let mut uri_cache = APP_STATE.uri_cache.write().await;
 
     match msg {
         StartFetchingFromClient(uri, req_params) => {
-            debug_println!("StartFetchingFromClient: {uri}");
+            println!("StartFetchingFromClient: {uri}");
+            let (tx, rx) = oneshot::channel();
             let entry = UriEntry {
                 response_body: None,
                 is_fetching: true,
@@ -124,7 +127,9 @@ async fn update_cache(msg: &UriCacheUpdateMessage) {
                 fetch_complete_time: None,
                 last_req_time: Instant::now(),
                 request_params: (*req_params).clone(),
-                clear_timer_creation_time: None
+                clear_timer_creation_time: None,
+                channel_tx: tx,
+                channel_rx: rx
             };
             uri_cache.insert(uri.to_string(), entry);
         },
@@ -135,7 +140,7 @@ async fn update_cache(msg: &UriCacheUpdateMessage) {
             }
         },
         StartFetchingFromRefresh(uri) => {
-            debug_println!("StartFetchingFromRefresh: {uri}");
+            println!("StartFetchingFromRefresh: {uri}");
             let current_item = uri_cache.get(uri)
             .expect("Expected a cached item, but did not find one. Accidentally deleted? {uri}");
 
@@ -147,12 +152,14 @@ async fn update_cache(msg: &UriCacheUpdateMessage) {
                 fetch_complete_time: None,
                 last_req_time: current_item.last_req_time,
                 request_params: current_item.request_params.clone(),
-                clear_timer_creation_time: None
+                clear_timer_creation_time: None,
+                channel_tx: current_item.channel_tx,
+                channel_rx: current_item.channel_rx,
             };
             uri_cache.insert(uri.to_string(), entry);
         }
         DeleteOrRefreshCache(uri, instant) => {
-            debug_println!("DeleteOrRefreshCache: {uri}");
+            println!("DeleteOrRefreshCache: {uri}");
             let cache_item = uri_cache.get(uri);
 
             let timer_mismatch_detected = 
@@ -176,16 +183,16 @@ async fn update_cache(msg: &UriCacheUpdateMessage) {
                     let uri = uri.clone();
                     task::spawn(async move {
                         let req_count = incr_count().await;
-                        debug_println!("Refreshing Cache: {uri}");
+                        println!("Refreshing Cache: {uri}");
                         background_refresh_cache(request_params.clone(), req_count, true).await;
                     });
             } else if (!timer_mismatch_detected) {
-                debug_println!("Deleting Cache (actually): {uri}");
+                println!("Deleting Cache (actually): {uri}");
                 uri_cache.remove(uri);
             }
         },
         FinishFetchingWithSuccess(uri, update_cache_entry) => {
-            debug_println!("FinishFetchingWithSuccess: {uri}");
+            println!("FinishFetchingWithSuccess: {uri}");
             let current_item = uri_cache.get(uri)
                 .expect("Expected a cached item, but did not find one. Accidentally deleted? {uri}");
 
@@ -197,12 +204,16 @@ async fn update_cache(msg: &UriCacheUpdateMessage) {
                 fetch_complete_time: Some(Instant::now()),
                 last_req_time: current_item.last_req_time,
                 request_params: current_item.request_params.clone(),
-                clear_timer_creation_time: None
+                clear_timer_creation_time: None,
+                channel_tx: current_item.channel_tx,
+                channel_rx: current_item.channel_rx,
             };
+
+            current_item.channel_tx.send(ResponseType::Success);
             uri_cache.insert(uri.to_string(), entry);
         },
         FinishFetchingWithError(uri) => {
-            debug_println!("FinishFetchingWithError: {uri}");
+            println!("FinishFetchingWithError: {uri}");
             let current_item = uri_cache.get(uri)
                 .expect("Expected a cached item, but did not find one. Accidentally deleted? {uri}");
 
@@ -214,12 +225,14 @@ async fn update_cache(msg: &UriCacheUpdateMessage) {
                 fetch_complete_time: Some(Instant::now()),
                 last_req_time: current_item.last_req_time,
                 request_params: current_item.request_params.clone(),
-                clear_timer_creation_time: None
+                clear_timer_creation_time: None,
+                channel_tx: current_item.channel_tx,
+                channel_rx: current_item.channel_rx,
             };
             uri_cache.insert(uri.to_string(), entry);
         },
         UpdateLatestReqTimestamp(uri) => {
-            debug_println!("UpdateLatestReqTimestamp: {uri}");
+            println!("UpdateLatestReqTimestamp: {uri}");
             let current_item = uri_cache.get_mut(uri);
             if current_item.is_some() {
                 current_item.unwrap().last_req_time = Instant::now();
@@ -239,21 +252,41 @@ async fn delay() {
     sleep(Duration::from_secs(timeout)).await;
 }
 
-async fn getCacheEntry(url: &Uri) -> Option<UriEntry> {
+struct CachedResponse {
+  body: Option<String>,
+  resp_headers: Option<HeaderMap>
+}
+
+async fn getCachedResponse(url: &Uri) -> Option<CachedResponse> {
     let response_cache = &APP_STATE.uri_cache.read().await;
 
     if response_cache.contains_key(url) {
         let cached_response = response_cache.get(url).unwrap();
-        return Some(cached_response.clone());
+        let body_and_headers = CachedResponse {
+            body: cached_response.response_body.clone(),
+            resp_headers: cached_response.resp_headers.clone()
+        };
+
+        return Some(body_and_headers);
     }
     None
 }
 
-async fn getCachedResponseLoop(url: &Uri) -> Result<UriEntry, CachedResponseError> {
-    loop {
-        let response = getCacheEntry(url).await;
-        match response {
-            Some(val) => {
+async fn waitForCachedResponse(url: &Uri) -> Result<UriEntry, CachedResponseError> {
+
+    let response_cache = &APP_STATE.uri_cache.read().await;
+
+    let channel_rx = match (response_cache.get(url)) {
+        None => {
+            return Err(CachedResponseError{message: format!("Response cache item is missing: {url}")})
+        },
+        Some(uri_entry) => uri_entry.channel_rx
+    };
+
+    let msg = channel_rx.await;
+
+    match msg {
+            Ok(resp_type) => {
                 if (val.response_body.is_some() && val.resp_headers.is_some()) {
                     return Ok(val);
                 } else if (val.is_fetching) {
@@ -265,12 +298,14 @@ async fn getCachedResponseLoop(url: &Uri) -> Result<UriEntry, CachedResponseErro
                 }
                 // else, continue the loop waiting
             }
-            None => return Err(CachedResponseError{message: format!("No cache entry found for uri: {url}")}),
+            _ => {
+
+            }
+            ResponseType::Error => return Err(CachedResponseError{message: format!("No cache entry found for uri: {url}")}),
         }
     }
-}
 async fn getCachedResponseOrTimeout(url: &Uri) -> Result<UriEntry, CachedResponseError> {
-    let cached_resp_fut = getCachedResponseLoop(url);
+    let cached_resp_fut = waitForCachedResponse(url);
     let sleep_statement = task::spawn(delay());
     let res = tokio::select! {
         _ = sleep_statement => Err(CachedResponseError{message: format!("Time out while waiting for cached resp for uri: {url}")}),
@@ -372,7 +407,7 @@ async fn clear_cache(mut req: Request<Body>) -> Result<hyper::Response<Body>, In
     let clear_cache_url = &req.uri().path().to_string();
 
     update_cache(&DeleteOrRefreshCache(clear_cache_url.to_string(), None)).await;
-    debug_println!("Deleted {clear_cache_url} from cache");
+    println!("Deleted {clear_cache_url} from cache");
 
     Ok(Response::builder()
         .status(StatusCode::OK)
@@ -404,7 +439,7 @@ async fn background_refresh_cache(request_params:RequestParams, count:u32, from_
 
     //http://host.docker.internal:5984{uri_path}{queryStr}"
     let fullURL = format!("{upstream_url}{uri_path}{queryStr}");
-    debug_println!("full URL: {fullURL}");
+    println!("full URL: {fullURL}");
 
     let mut header_map_temp = headerMap.clone();
     header_map_temp.remove("if-none-match"); // We want upstream URLs to fetch full response
@@ -412,7 +447,7 @@ async fn background_refresh_cache(request_params:RequestParams, count:u32, from_
 
     let res = tokio::select! {
         _ = sleep_statement => {
-            debug_println!("timed out while doing background fetch {uri_path}");
+            println!("timed out while doing background fetch {uri_path}");
             update_cache(&FinishFetchingWithError(uri_path.clone())).await;
             {Ok(Response::builder()
                 .status(StatusCode::INTERNAL_SERVER_ERROR)
@@ -423,16 +458,16 @@ async fn background_refresh_cache(request_params:RequestParams, count:u32, from_
         response = proxy_call => {
             match response {
                 Ok(response) => {
-                    debug_dbg!(&response);
+                    dbg!(&response);
                     let resp_headers = response.headers().clone();
                     let proxy_text = match response.text().await {
                         Ok(p) => {
-                            // debug_println!("FULL RESPONSE:{}", p);
+                            // println!("FULL RESPONSE:{}", p);
                             p
                         },
                         Err(_) => {
                             update_cache(&FinishFetchingWithError(uri_path.clone())).await;
-                            debug_println!("Error getting body from {}", &uri_path);
+                            println!("Error getting body from {}", &uri_path);
                             return Ok(Response::builder()
                                 .status(StatusCode::INTERNAL_SERVER_ERROR)
                                 .body(Body::from(format!("error response when getting body text from {uri_path}")))
@@ -446,14 +481,14 @@ async fn background_refresh_cache(request_params:RequestParams, count:u32, from_
                     // Not sure if this should be in its own task
                     task::spawn(async move {
                         let uri_c = uri.clone();
-                        debug_println!("{count}: Updating cache!");
+                        println!("{count}: Updating cache!");
                         let update_entry = UpdateCacheEntry {
                             resp_headers: Some(c_resp_headers),
                             response_body: Some(c_body)
                         };
                         
                         update_cache(&FinishFetchingWithSuccess(uri_c, update_entry)).await;
-                        debug_println!("{count}: Inserted into cache!");
+                        println!("{count}: Inserted into cache!");
 
                         task::spawn(async move {
                             let env = ENV.read().await;
@@ -463,7 +498,7 @@ async fn background_refresh_cache(request_params:RequestParams, count:u32, from_
                             update_cache(&SetClearTimerStart(uri, clear_timer_creation_time.unwrap())).await;
                             sleep(Duration::from_secs(cache_expiry_time)).await;
                             {
-                                debug_println!("Clearing old cache for: {uri_c}");
+                                println!("Clearing old cache for: {uri_c}");
                                 update_cache(&DeleteOrRefreshCache(uri_c, clear_timer_creation_time)).await;
                             }
                         });
@@ -472,7 +507,7 @@ async fn background_refresh_cache(request_params:RequestParams, count:u32, from_
                     Ok(build_response(&proxy_text, &resp_headers, &request_etag))
                 }
                 Err(error) => {
-                    debug_println!("error in response from background fetch {uri_path} {error:?}");
+                    println!("error in response from background fetch {uri_path} {error:?}");
                     update_cache(&FinishFetchingWithError(uri_path.clone())).await;
                     Ok(Response::builder()
                                 .status(StatusCode::INTERNAL_SERVER_ERROR)
@@ -489,11 +524,11 @@ async fn handle(
     _client_ip: IpAddr,
     mut req: Request<Body>,
 ) -> Result<hyper::Response<Body>, Infallible> {
-    debug_println!("in handle");
+    println!("in handle");
 
     let method = req.method().clone();
     let count = incr_count().await;
-    debug_println!("{count} requests");
+    println!("{count} requests");
     let body = read_json_body(&mut req).await;
     let pathAndQuery = req.uri().path_and_query();
 
@@ -503,21 +538,21 @@ async fn handle(
     let path = pathAndQuery.unwrap().path();
 
     let headerMap: HeaderMap = req.headers().clone();
-    debug_println!("HEADERS: {:?}", headerMap);
+    println!("HEADERS: {:?}", headerMap);
 
     let request_etag = req.headers().get("if-none-match").cloned();
 
     if (headerMap.contains_key("clear-cache")) {
         return clear_cache(req).await;
     }
-    debug_println!("PATH: {path}");
-    debug_println!("BODY: {body:?}");
+    println!("PATH: {path}");
+    println!("BODY: {body:?}");
     let queryStr = match query {
         Some(q) => format!("?{q}"),
         None => "".to_string(),
     };
     if let Some(q) = query {
-        debug_println!("QUERY: {q}");
+        println!("QUERY: {q}");
     }
     let uri_path = &req.uri().path().to_string();
     let cached_resp = getCacheEntry(uri_path).await;
@@ -529,19 +564,19 @@ async fn handle(
         });
 
         if uri_entry.response_body.is_some() {
-            debug_println!("{count} Returning from cache!");
+            println!("{count} Returning from cache!");
             return Ok(build_response(&uri_entry.response_body.unwrap(),
                 &uri_entry.resp_headers.unwrap(), &request_etag));
         }
     }
 
-    debug_println!("{count}: no cache found... {uri_path}");
+    println!("{count}: no cache found... {uri_path}");
     let is_fetching = is_fetching_uri(uri_path).await;
 
     if is_fetching {
-        debug_println!("{count}: could not get write lock. waiting for read lock");
+        println!("{count}: could not get write lock. waiting for read lock");
         let cached_resp = getCachedResponseOrTimeout(uri_path).await;
-        debug_println!("{count}: got read lock");
+        println!("{count}: got read lock");
         if cached_resp.is_ok() {
             let x = cached_resp.unwrap();
             return Ok(build_response(&x.response_body.unwrap(), &x.resp_headers.unwrap(), &request_etag));
@@ -583,6 +618,6 @@ async fn main() {
     println!("Running server on {:?}", addr);
 
     if let Err(e) = server.await {
-        println!("server error: {}", e);
+        eprintln!("server error: {}", e);
     }
 }
